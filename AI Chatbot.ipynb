{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.5)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: click in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: regex in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (2020.7.14)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (4.48.2)\n",
      "Collecting tflearn\n",
      "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tflearn) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tflearn) (1.15.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tflearn) (7.2.0)\n",
      "Building wheels for collected packages: tflearn\n",
      "  Building wheel for tflearn (setup.py): started\n",
      "  Building wheel for tflearn (setup.py): finished with status 'done'\n",
      "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127304 sha256=8d6df54d2d300cf9c546bd420e96f8a0d6d6ebd3d44a33dfb7d30a22238506a6\n",
      "  Stored in directory: c:\\users\\ammuuu\\appdata\\local\\pip\\cache\\wheels\\5f\\14\\2e\\1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\n",
      "Successfully built tflearn\n",
      "Installing collected packages: tflearn\n",
      "Successfully installed tflearn-0.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\ammuuu\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'How are you', 'Is anyone there?', 'Hello', 'Good day', 'Whats up'], 'responses': ['Hello!', 'Good to see you again!', 'Hi there, how can I help?'], 'context_set': ''}, {'tag': 'goodbye', 'patterns': ['cya', 'See you later', 'Goodbye', 'I am Leaving', 'Have a Good day'], 'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'], 'context_set': ''}, {'tag': 'age', 'patterns': ['how old', 'how old is tim', 'what is your age', 'how old are you', 'age?'], 'responses': ['I am 18 years old!', '18 years young!'], 'context_set': ''}, {'tag': 'name', 'patterns': ['what is your name', 'what should I call you', 'whats your name?'], 'responses': ['You can call me Tim.', \"I'm Tim!\", \"I'm Tim aka Tech With Tim.\"], 'context_set': ''}, {'tag': 'shop', 'patterns': ['Id like to buy something', 'whats on the menu', 'what do you reccommend?', 'could i get something to eat'], 'responses': ['We sell chocolate chip cookies for $2!', 'Cookies are on the menu!'], 'context_set': ''}, {'tag': 'hours', 'patterns': ['when are you guys open', 'what are your hours', 'hours of operation'], 'responses': ['We are open 7am-4pm Monday-Friday!'], 'context_set': ''}]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"intents.json\") as intents:\n",
    "    data = json.load(intents)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'tag': 'greeting',\n",
       "  'patterns': ['Hi',\n",
       "   'How are you',\n",
       "   'Is anyone there?',\n",
       "   'Hello',\n",
       "   'Good day',\n",
       "   'Whats up'],\n",
       "  'responses': ['Hello!',\n",
       "   'Good to see you again!',\n",
       "   'Hi there, how can I help?'],\n",
       "  'context_set': ''},\n",
       " {'tag': 'goodbye',\n",
       "  'patterns': ['cya',\n",
       "   'See you later',\n",
       "   'Goodbye',\n",
       "   'I am Leaving',\n",
       "   'Have a Good day'],\n",
       "  'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'],\n",
       "  'context_set': ''},\n",
       " {'tag': 'age',\n",
       "  'patterns': ['how old',\n",
       "   'how old is tim',\n",
       "   'what is your age',\n",
       "   'how old are you',\n",
       "   'age?'],\n",
       "  'responses': ['I am 18 years old!', '18 years young!'],\n",
       "  'context_set': ''},\n",
       " {'tag': 'name',\n",
       "  'patterns': ['what is your name',\n",
       "   'what should I call you',\n",
       "   'whats your name?'],\n",
       "  'responses': ['You can call me Tim.',\n",
       "   \"I'm Tim!\",\n",
       "   \"I'm Tim aka Tech With Tim.\"],\n",
       "  'context_set': ''},\n",
       " {'tag': 'shop',\n",
       "  'patterns': ['Id like to buy something',\n",
       "   'whats on the menu',\n",
       "   'what do you reccommend?',\n",
       "   'could i get something to eat'],\n",
       "  'responses': ['We sell chocolate chip cookies for $2!',\n",
       "   'Cookies are on the menu!'],\n",
       "  'context_set': ''},\n",
       " {'tag': 'hours',\n",
       "  'patterns': ['when are you guys open',\n",
       "   'what are your hours',\n",
       "   'hours of operation'],\n",
       "  'responses': ['We are open 7am-4pm Monday-Friday!'],\n",
       "  'context_set': ''}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['intents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi']\n",
      "['How', 'are', 'you']\n",
      "['Is', 'anyone', 'there', '?']\n",
      "['Hello']\n",
      "['Good', 'day']\n",
      "['Whats', 'up']\n",
      "['cya']\n",
      "['See', 'you', 'later']\n",
      "['Goodbye']\n",
      "['I', 'am', 'Leaving']\n",
      "['Have', 'a', 'Good', 'day']\n",
      "['how', 'old']\n",
      "['how', 'old', 'is', 'tim']\n",
      "['what', 'is', 'your', 'age']\n",
      "['how', 'old', 'are', 'you']\n",
      "['age', '?']\n",
      "['what', 'is', 'your', 'name']\n",
      "['what', 'should', 'I', 'call', 'you']\n",
      "['whats', 'your', 'name', '?']\n",
      "['Id', 'like', 'to', 'buy', 'something']\n",
      "['whats', 'on', 'the', 'menu']\n",
      "['what', 'do', 'you', 'reccommend', '?']\n",
      "['could', 'i', 'get', 'something', 'to', 'eat']\n",
      "['when', 'are', 'you', 'guys', 'open']\n",
      "['what', 'are', 'your', 'hours']\n",
      "['hours', 'of', 'operation']\n"
     ]
    }
   ],
   "source": [
    "#all words\n",
    "words = []\n",
    "#the possible labels\n",
    "labels = []\n",
    "#will hold the patterns\n",
    "docs_x = []\n",
    "#will hold the label for each pattern\n",
    "docs_y = []\n",
    "\n",
    "#loop through the intent dictionary\n",
    "for intent in data['intents']:\n",
    "    #loop through each pattern in each patterns list\n",
    "    for pattern in intent['patterns']:\n",
    "        #tokenize basically separates each word in a pattern and puts the words into a list\n",
    "        wrds = nltk.word_tokenize(pattern)\n",
    "        print(wrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "430"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for intent in data['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        wrds = nltk.word_tokenize(pattern)\n",
    "        #add all the wrds into words\n",
    "        words.extend(wrds)\n",
    "        docs_x.append(pattern)\n",
    "        docs_y.append(intent['tag'])\n",
    "        \n",
    "    if intent['tag'] not in labels:\n",
    "        labels.append(intent['tag'])\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removes the ends of the words\n",
    "words = [stemmer.stem(w.lower()) for w in words]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove duplicates\n",
    "words = sorted(list(set(words)))\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One hot encoding\n",
    "#the mapping is [the, she, he, him, they, was, a, guy, person]\n",
    "#one-hot representation -> [0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
    "#he was a person\n",
    "#this is a bag of words\n",
    "\n",
    "training = []\n",
    "output = []\n",
    "\n",
    "#basically what we are doing here is one-hot encoding the data\n",
    "out_empty = [0 for _ in range(len(labels))]\n",
    "for x, doc in enumerate(docs_x):\n",
    "    bag = []\n",
    "    wrds = [stemmer.stem(w) for w in doc]\n",
    "    \n",
    "    for w in words:\n",
    "        if w in wrds:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "    output_row = out_empty[:]\n",
    "    output_row[labels.index(docs_y[x])] * 1\n",
    "    training.append(bag)\n",
    "    output.append(output_row)\n",
    "    \n",
    "training = numpy.array(training)\n",
    "output = numpy.array(output)\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
